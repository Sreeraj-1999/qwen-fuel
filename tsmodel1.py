import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import optuna
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict
import logging
import json
import pickle
from datetime import datetime
import math

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

# ============================================================================
# PYDANTIC MODELS
# ============================================================================

class InputFeaturesModel(BaseModel):
    load: str  # Load tag name
    efd_features: List[str]  # EFD feature names
    important_features: List[str]  # Important feature names from MI

class OutputFeaturesModel(BaseModel):
    load: str  # Load tag name
    efd_features: List[str]  # EFD features to forecast

class TrainInputModel(BaseModel):
    imo_number: str
    input_features: InputFeaturesModel
    output_features: OutputFeaturesModel
    excel_path: str  # Path to aggregated Excel/CSV file

# ============================================================================
# POSITIONAL ENCODING
# ============================================================================

class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        return x + self.pe[:, :x.size(1), :]

# ============================================================================
# LSTM-TRANSFORMER ENCODER LAYER
# ============================================================================

class LSTMTransformerEncoderLayer(nn.Module):
    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):
        super(LSTMTransformerEncoderLayer, self).__init__()
        self.lstm = nn.LSTM(d_model, d_model, batch_first=True)
        self.mha = nn.MultiheadAttention(d_model, num_heads, dropout=dropout_rate, batch_first=True)
        self.ffn = nn.Sequential(
            nn.Linear(d_model, dff),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(dff, d_model)
        )
        self.layernorm1 = nn.LayerNorm(d_model)
        self.layernorm2 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout_rate)
        self.dropout2 = nn.Dropout(dropout_rate)
    
    def forward(self, x, mask=None):
        # LSTM
        lstm_out, (h, c) = self.lstm(x)
        
        # Multi-head attention
        attn_out, _ = self.mha(lstm_out, lstm_out, lstm_out, attn_mask=mask)
        attn_out = self.dropout1(attn_out)
        out1 = self.layernorm1(lstm_out + attn_out)
        
        # Feed-forward
        ffn_out = self.ffn(out1)
        ffn_out = self.dropout2(ffn_out)
        out2 = self.layernorm2(out1 + ffn_out)
        
        return out2, h, c

# ============================================================================
# LSTM-TRANSFORMER DECODER LAYER
# ============================================================================

class LSTMTransformerDecoderLayer(nn.Module):
    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):
        super(LSTMTransformerDecoderLayer, self).__init__()
        self.lstm = nn.LSTM(d_model, d_model, batch_first=True)
        self.mha1 = nn.MultiheadAttention(d_model, num_heads, dropout=dropout_rate, batch_first=True)
        self.mha2 = nn.MultiheadAttention(d_model, num_heads, dropout=dropout_rate, batch_first=True)
        self.ffn = nn.Sequential(
            nn.Linear(d_model, dff),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(dff, d_model)
        )
        self.layernorm1 = nn.LayerNorm(d_model)
        self.layernorm2 = nn.LayerNorm(d_model)
        self.layernorm3 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout_rate)
        self.dropout2 = nn.Dropout(dropout_rate)
        self.dropout3 = nn.Dropout(dropout_rate)
    
    def forward(self, x, enc_output, tgt_mask=None, memory_mask=None):
        # LSTM
        lstm_out, (h, c) = self.lstm(x)
        
        # Self-attention
        attn1, _ = self.mha1(lstm_out, lstm_out, lstm_out, attn_mask=tgt_mask)
        attn1 = self.dropout1(attn1)
        out1 = self.layernorm1(lstm_out + attn1)
        
        # Cross-attention with encoder output
        attn2, _ = self.mha2(out1, enc_output, enc_output, attn_mask=memory_mask)
        attn2 = self.dropout2(attn2)
        out2 = self.layernorm2(out1 + attn2)
        
        # Feed-forward
        ffn_out = self.ffn(out2)
        ffn_out = self.dropout3(ffn_out)
        out3 = self.layernorm3(out2 + ffn_out)
        
        return out3

# ============================================================================
# FULL ENCODER
# ============================================================================

class LSTMTransformerEncoder(nn.Module):
    def __init__(self, num_layers, d_model, num_heads, dff, input_dim, dropout_rate=0.1):
        super(LSTMTransformerEncoder, self).__init__()
        self.d_model = d_model
        self.input_projection = nn.Linear(input_dim, d_model)
        self.pos_encoding = PositionalEncoding(d_model)
        self.layers = nn.ModuleList([
            LSTMTransformerEncoderLayer(d_model, num_heads, dff, dropout_rate)
            for _ in range(num_layers)
        ])
        self.dropout = nn.Dropout(dropout_rate)
    
    def forward(self, x, mask=None):
        x = self.input_projection(x)
        x = x * math.sqrt(self.d_model)
        x = self.pos_encoding(x)
        x = self.dropout(x)
        
        for layer in self.layers:
            x, h, c = layer(x, mask)
        
        return x

# ============================================================================
# FULL DECODER
# ============================================================================

class LSTMTransformerDecoder(nn.Module):
    def __init__(self, num_layers, d_model, num_heads, dff, output_dim, dropout_rate=0.1):
        super(LSTMTransformerDecoder, self).__init__()
        self.d_model = d_model
        self.input_projection = nn.Linear(output_dim, d_model)
        self.pos_encoding = PositionalEncoding(d_model)
        self.layers = nn.ModuleList([
            LSTMTransformerDecoderLayer(d_model, num_heads, dff, dropout_rate)
            for _ in range(num_layers)
        ])
        self.dropout = nn.Dropout(dropout_rate)
        self.output_projection = nn.Linear(d_model, output_dim)
    
    def forward(self, x, enc_output, tgt_mask=None, memory_mask=None):
        x = self.input_projection(x)
        x = x * math.sqrt(self.d_model)
        x = self.pos_encoding(x)
        x = self.dropout(x)
        
        for layer in self.layers:
            x = layer(x, enc_output, tgt_mask, memory_mask)
        
        x = self.output_projection(x)
        return x

# ============================================================================
# COMPLETE MODEL
# ============================================================================

class LSTMTransformerSeq2Seq(nn.Module):
    def __init__(self, num_layers, d_model, num_heads, dff, input_dim, output_dim, dropout_rate=0.1):
        super(LSTMTransformerSeq2Seq, self).__init__()
        self.encoder = LSTMTransformerEncoder(num_layers, d_model, num_heads, dff, input_dim, dropout_rate)
        self.decoder = LSTMTransformerDecoder(num_layers, d_model, num_heads, dff, output_dim, dropout_rate)
    
    def forward(self, src, tgt):
        enc_output = self.encoder(src)
        dec_output = self.decoder(tgt, enc_output)
        return dec_output

# ============================================================================
# DATASET
# ============================================================================

class TimeSeriesDataset(Dataset):
    def __init__(self, input_data, output_data, timestamps):
        self.input_data = torch.FloatTensor(input_data)
        self.output_data = torch.FloatTensor(output_data)
        self.timestamps = timestamps
    
    def __len__(self):
        return len(self.input_data)
    
    def __getitem__(self, idx):
        return self.input_data[idx], self.output_data[idx], self.timestamps[idx]

# ============================================================================
# TRAINING FUNCTIONS
# ============================================================================

def create_sequences(df, input_cols, output_cols, timestamp_col, lookback=336, horizon=336):
    """Create sliding window sequences"""
    input_sequences = []
    output_sequences = []
    timestamps = []
    
    for i in range(0,len(df) - lookback - horizon + 1,24):
        # Input: lookback hours
        input_seq = df[input_cols].iloc[i:i+lookback].values
        
        # Output: next horizon hours
        output_seq = df[output_cols].iloc[i+lookback:i+lookback+horizon].values
        
        # Timestamp of the last input point
        timestamp = df[timestamp_col].iloc[i+lookback-1]
        
        input_sequences.append(input_seq)
        output_sequences.append(output_seq)
        timestamps.append(timestamp)
    
    return np.array(input_sequences), np.array(output_sequences), timestamps

def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, patience, device):
    """Training loop with early stopping"""
    best_val_loss = float('inf')
    patience_counter = 0
    best_model_state = None
    
    train_losses = []
    val_losses = []
    
    for epoch in range(epochs):
        # Training
        model.train()
        train_loss = 0.0
        for src, tgt, _ in train_loader:
            src, tgt = src.to(device), tgt.to(device)
            
            # Teacher forcing: use actual target as decoder input (shifted)
            tgt_input = torch.zeros_like(tgt)
            tgt_input[:, 1:, :] = tgt[:, :-1, :]
            
            optimizer.zero_grad()
            output = model(src, tgt_input)
            loss = criterion(output, tgt)
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            train_loss += loss.item()
        
        train_loss /= len(train_loader)
        train_losses.append(train_loss)
        
        # Validation
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for src, tgt, _ in val_loader:
                src, tgt = src.to(device), tgt.to(device)
                tgt_input = torch.zeros_like(tgt)
                tgt_input[:, 1:, :] = tgt[:, :-1, :]
                
                output = model(src, tgt_input)
                loss = criterion(output, tgt)
                val_loss += loss.item()
        
        val_loss /= len(val_loader)
        val_losses.append(val_loss)
        
        # Learning rate scheduling
        scheduler.step(val_loss)
        
        logger.info(f"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}")
        
        # Early stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            best_model_state = model.state_dict().copy()
        else:
            patience_counter += 1
            if patience_counter >= patience:
                logger.info(f"Early stopping triggered at epoch {epoch+1}")
                break
    
    # Load best model
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    return model, train_losses, val_losses, best_val_loss

# ============================================================================
# OPTUNA OBJECTIVE
# ============================================================================

def objective(trial, train_data, val_data, input_dim, output_dim, device):
    """Optuna objective function for hyperparameter tuning"""
    
    # Hyperparameters to tune
    d_model = trial.suggest_categorical('d_model', [64, 128, 256])
    num_heads = trial.suggest_categorical('num_heads', [4, 8])
    num_layers = trial.suggest_int('num_layers', 2, 4)
    dff = trial.suggest_categorical('dff', [128, 256, 512])
    dropout = trial.suggest_float('dropout', 0.3, 0.5)
    lr = trial.suggest_loguniform('lr', 1e-4, 1e-3)
    batch_size = trial.suggest_categorical('batch_size', [16, 32])
    
    # Create model
    model = LSTMTransformerSeq2Seq(
        num_layers=num_layers,
        d_model=d_model,
        num_heads=num_heads,
        dff=dff,
        input_dim=input_dim,
        output_dim=output_dim,
        dropout_rate=dropout
    ).to(device)
    
    # Data loaders
    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
    
    # Loss and optimizer
    criterion = nn.HuberLoss(delta=1.0)  # Robust to outliers
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
    
    # Train
    _, _, _, best_val_loss = train_model(
        model, train_loader, val_loader, criterion, optimizer, scheduler,
        epochs=50,  # Reduced for tuning
        patience=10,
        device=device
    )
    
    return best_val_loss

# ============================================================================
# MAIN TRAINING ENDPOINT
# ============================================================================

@app.post("/train/timeseries/")
async def train_timeseries(input_json: TrainInputModel):
    logger.info("ðŸš€ Starting Time Series Model Training...")
    
    try:
        # Read data
        logger.info(f"ðŸ“Š Reading data from {input_json.excel_path}")
        if input_json.excel_path.endswith('.csv'):
            df = pd.read_csv(input_json.excel_path)
        else:
            df = pd.read_excel(input_json.excel_path)
        
        logger.info(f"âœ… Data loaded: {df.shape}")
        
        # Identify timestamp column
        timestamp_col = None
        for col in ['timestamp', 'time', 'TI_UTC_act_ts@AVG', 'datetime']:
            if col in df.columns:
                timestamp_col = col
                break
        
        if timestamp_col is None:
            raise HTTPException(status_code=400, detail="No timestamp column found")
        
        # Convert timestamp to datetime
        df[timestamp_col] = pd.to_datetime(df[timestamp_col])
        df = df.sort_values(timestamp_col)
        
        # Prepare input and output columns
        input_cols = [input_json.input_features.load] + \
                     input_json.input_features.efd_features + \
                     input_json.input_features.important_features
        
        output_cols = [input_json.output_features.load] + \
                      input_json.output_features.efd_features
        
        logger.info(f"ðŸ“‹ Input features ({len(input_cols)}): {input_cols}")
        logger.info(f"ðŸ“‹ Output features ({len(output_cols)}): {output_cols}")
        
        # Check if all columns exist
        missing_cols = [col for col in input_cols + output_cols if col not in df.columns]
        if missing_cols:
            raise HTTPException(status_code=400, detail=f"Missing columns: {missing_cols}")
        
        # Create sequences
        logger.info("ðŸ”„ Creating sequences...")
        X, y, timestamps = create_sequences(df, input_cols, output_cols, timestamp_col)
        logger.info(f"âœ… Created {len(X)} sequences")
        
        if len(X) < 10:
            raise HTTPException(status_code=400, detail="Insufficient data for training (need at least 10 sequences)")
        
        # Scale data
        logger.info("ðŸ“Š Scaling data...")
        input_scaler = StandardScaler()
        output_scaler = StandardScaler()
        
        # Reshape for scaling
        X_reshaped = X.reshape(-1, X.shape[-1])
        y_reshaped = y.reshape(-1, y.shape[-1])
        
        X_scaled = input_scaler.fit_transform(X_reshaped).reshape(X.shape)
        y_scaled = output_scaler.fit_transform(y_reshaped).reshape(y.shape)
        
        # Train-validation split (80-20)
        split_idx = int(0.8 * len(X_scaled))
        X_train, X_val = X_scaled[:split_idx], X_scaled[split_idx:]
        y_train, y_val = y_scaled[:split_idx], y_scaled[split_idx:]
        timestamps_train = timestamps[:split_idx]
        timestamps_val = timestamps[split_idx:]
        
        logger.info(f"âœ… Train: {len(X_train)}, Validation: {len(X_val)}")
        
        # Create datasets
        train_dataset = TimeSeriesDataset(X_train, y_train, timestamps_train)
        val_dataset = TimeSeriesDataset(X_val, y_val, timestamps_val)
        
        # Device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ðŸ–¥ï¸  Using device: {device}")
        
        # Hyperparameter tuning with Optuna
        logger.info("ðŸ” Starting hyperparameter tuning (50 trials)...")
        study = optuna.create_study(direction='minimize')
        study.optimize(
            lambda trial: objective(trial, train_dataset, val_dataset, X.shape[-1], y.shape[-1], device),
            n_trials=50,
            show_progress_bar=True
        )
        
        best_params = study.best_params
        logger.info(f"âœ… Best hyperparameters: {best_params}")
        
        # Train final model with best params
        logger.info("ðŸ‹ï¸ Training final model with best hyperparameters...")
        final_model = LSTMTransformerSeq2Seq(
            num_layers=best_params['num_layers'],
            d_model=best_params['d_model'],
            num_heads=best_params['num_heads'],
            dff=best_params['dff'],
            input_dim=X.shape[-1],
            output_dim=y.shape[-1],
            dropout_rate=best_params['dropout']
        ).to(device)
        
        train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'], shuffle=False)
        
        criterion = nn.HuberLoss(delta=1.0)
        optimizer = optim.AdamW(final_model.parameters(), lr=best_params['lr'], weight_decay=1e-5)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)
        
        final_model, train_losses, val_losses, best_val_loss = train_model(
            final_model, train_loader, val_loader, criterion, optimizer, scheduler,
            epochs=200,
            patience=15,
            device=device
        )
        
        # Save model and scalers
        model_dir = f"models/{input_json.imo_number}"
        import os
        os.makedirs(model_dir, exist_ok=True)
        
        model_path = f"{model_dir}/model.pth"
        input_scaler_path = f"{model_dir}/input_scaler.pkl"
        output_scaler_path = f"{model_dir}/output_scaler.pkl"
        metadata_path = f"{model_dir}/metadata.json"
        
        torch.save(final_model.state_dict(), model_path)
        
        with open(input_scaler_path, 'wb') as f:
            pickle.dump(input_scaler, f)
        
        with open(output_scaler_path, 'wb') as f:
            pickle.dump(output_scaler, f)
        
        metadata = {
            "imo_number": input_json.imo_number,
            "input_features": input_cols,
            "output_features": output_cols,
            "input_dim": X.shape[-1],
            "output_dim": y.shape[-1],
            "best_params": best_params,
            "best_val_loss": float(best_val_loss),
            "train_loss": float(train_losses[-1]),
            "training_date": str(datetime.now()),
            "num_sequences": len(X)
        }
        
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        logger.info(f"âœ… Model saved to {model_path}")
        logger.info("ðŸŽ‰ Training completed successfully!")
        
        return {
            "success": True,
            "imo_number": input_json.imo_number,
            "model_path": model_path,
            "best_hyperparameters": best_params,
            "best_validation_loss": float(best_val_loss),
            "final_train_loss": float(train_losses[-1]),
            "final_val_loss": float(val_losses[-1]),
            "num_epochs": len(train_losses),
            "num_sequences": len(X),
            "input_features": input_cols,
            "output_features": output_cols
        }
        
    except Exception as e:
        logger.error(f"âŒ Training failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)